{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "import matplotlib as mlp\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import PIL\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
        "import pathlib\n",
        "import torch.nn.functional as F\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import matplotlib.ticker as ticker\n",
        "import heapq\n",
        "from collections import defaultdict\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-05-17T13:10:40.741467Z",
          "iopub.execute_input": "2023-05-17T13:10:40.742394Z",
          "iopub.status.idle": "2023-05-17T13:10:52.578098Z",
          "shell.execute_reply.started": "2023-05-17T13:10:40.742316Z",
          "shell.execute_reply": "2023-05-17T13:10:52.576879Z"
        },
        "trusted": true,
        "id": "2LEl6PNXZ0qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej3U1wbrbLyf",
        "outputId": "dbf06e76-a36d-4e56-f59d-5369b42b437f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=c1c227384c2ed070e14ccd0883a9ccd62d687c72a49080b7d645ef935bb8c21b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.23.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOJqiGKBaGbT",
        "outputId": "8418a2b2-c033-4756-a0ba-a2d4c65db713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "X_val = []\n",
        "Y_val = []\n",
        "X_test = []\n",
        "Y_test = []"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T13:10:52.580212Z",
          "iopub.execute_input": "2023-05-17T13:10:52.580939Z",
          "iopub.status.idle": "2023-05-17T13:10:52.586449Z",
          "shell.execute_reply.started": "2023-05-17T13:10:52.580900Z",
          "shell.execute_reply": "2023-05-17T13:10:52.585206Z"
        },
        "trusted": true,
        "id": "rBanAoluZ0qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tsv_file = open(\"/content/drive/MyDrive/Assignment3/aksharantar_sampled/tel/tel_train.csv\")\n",
        "read_tsv = csv.reader(tsv_file)\n",
        "\n",
        "pad1 = \"\\t\"\n",
        "space1 = \"\\n\"\n",
        "for i in read_tsv:   \n",
        "    Y_train.append(i[1])\n",
        "    X_train.append(i[0])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "val_tsv_file = open(\"/content/drive/MyDrive/Assignment3/aksharantar_sampled/tel/tel_valid.csv\")\n",
        "val_read_tsv = csv.reader(val_tsv_file)\n",
        "pad2 = \"\\t\"\n",
        "space2 = \"\\n\"\n",
        "for i in val_read_tsv:\n",
        "    Y_val.append(i[1])\n",
        "    X_val.append(i[0])\n",
        "X_val= np.array(X_val)\n",
        "\n",
        "test_tsv_file = open(\"/content/drive/MyDrive/Assignment3/aksharantar_sampled/tel/tel_test.csv\")\n",
        "test_read_tsv = csv.reader(test_tsv_file)\n",
        "pad3 = \"\\t\"\n",
        "space3 = \"\\n\"\n",
        "for i in test_read_tsv:\n",
        "    Y_test.append(i[1])\n",
        "    X_test.append(i[0])\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "trainsize=len(X_train)\n",
        "testsize = len(X_test)\n",
        "validationsize = len(X_val)\n",
        "\n",
        "print(\"Number of Training samples:\", trainsize)\n",
        "print(\"Number of Test Samples:\" , testsize)\n",
        "print(\"Number of Validation Samples:\", validationsize)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T13:10:52.588557Z",
          "iopub.execute_input": "2023-05-17T13:10:52.589072Z",
          "iopub.status.idle": "2023-05-17T13:10:52.870757Z",
          "shell.execute_reply.started": "2023-05-17T13:10:52.589006Z",
          "shell.execute_reply": "2023-05-17T13:10:52.869778Z"
        },
        "trusted": true,
        "id": "t4XI1NCaZ0qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de4a431-9cad-4fda-b1fe-0ff678193f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training samples: 51200\n",
            "Number of Test Samples: 4096\n",
            "Number of Validation Samples: 4096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = np.array(Y_train)\n",
        "for i in range(Y_train.shape[0]):\n",
        "    Y_train[i] = pad1 + Y_train[i] + space1\n",
        "\n",
        "Y_val = np.array(Y_val)\n",
        "for i in range(Y_val.shape[0]):\n",
        "    Y_val[i] = pad2 + Y_val[i] + space2\n",
        "    \n",
        "Y_test = np.array(Y_test)\n",
        "for i in range(Y_test.shape[0]):\n",
        "    Y_test[i] = pad3+ Y_test[i] + space3\n"
      ],
      "metadata": {
        "id": "YzjJk6R7aE0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traintargetsize=len(Y_train)\n",
        "testtargetsize = len(Y_test)\n",
        "testtargetsize = len(Y_val)\n",
        "print(\"TrainSize of Target \",traintargetsize)\n",
        "print(\"TrainSize of Target \",testtargetsize)\n",
        "print(\"TrainSize of Target \",testtargetsize)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "evdQfsetZ0qj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06abfb82-c91f-4640-df90-f575cd601001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainSize of Target  51200\n",
            "TrainSize of Target  4096\n",
            "TrainSize of Target  4096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_corpus = set()\n",
        "output_corpus = set()\n",
        "input_corpus = set(char for word in X_train for char in word if char not in input_corpus)\n",
        "output_corpus = set(char for word in Y_train for char in word if char not in output_corpus)\n",
        "input_corpus.add(\" \")\n",
        "output_corpus.add(\" \")\n",
        "input_corpus = sorted(list(input_corpus))\n",
        "output_corpus = sorted(list(output_corpus))\n",
        "val_input_corpus = set()\n",
        "val_output_corpus = set()\n",
        "max_encoder_seq_length = max([len(txt) for txt in X_train]) + 2\n",
        "max_decoder_seq_length = max([len(txt) for txt in Y_train])\n",
        "\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "val_input_corpus = set(char for word in X_val for char in word if char not in val_input_corpus)\n",
        "val_output_corpus = set(char for word in Y_val for char in word if char not in val_output_corpus)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T13:10:52.873994Z",
          "iopub.execute_input": "2023-05-17T13:10:52.874337Z",
          "iopub.status.idle": "2023-05-17T13:10:53.233021Z",
          "shell.execute_reply.started": "2023-05-17T13:10:52.874305Z",
          "shell.execute_reply": "2023-05-17T13:10:53.231840Z"
        },
        "trusted": true,
        "id": "MqHk0njfZ0qk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b5f16b-b623-44c3-e1b3-65e4b3708374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_encoder_tokens = len(input_corpus)\n",
        "num_decoder_tokens = len(output_corpus)\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T13:10:53.245617Z",
          "iopub.execute_input": "2023-05-17T13:10:53.246376Z",
          "iopub.status.idle": "2023-05-17T13:10:53.256591Z",
          "shell.execute_reply.started": "2023-05-17T13:10:53.246344Z",
          "shell.execute_reply": "2023-05-17T13:10:53.255162Z"
        },
        "trusted": true,
        "id": "iVEOiAJ1Z0ql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf13c62-59b3-42b5-e7d3-df98bf266d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "input_data = np.zeros((max_encoder_seq_length,len(X_train)), dtype=\"int64\")\n",
        "target_data = np.zeros((max_decoder_seq_length,len(X_train)), dtype=\"int64\")\n",
        "input_data_val = np.zeros((max_encoder_seq_length,len(X_val)), dtype=\"int64\")\n",
        "target_data_val = np.zeros((max_decoder_seq_length,len(X_val)), dtype=\"int64\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T13:10:53.258303Z",
          "iopub.execute_input": "2023-05-17T13:10:53.258778Z",
          "iopub.status.idle": "2023-05-17T13:10:53.270246Z",
          "shell.execute_reply.started": "2023-05-17T13:10:53.258709Z",
          "shell.execute_reply": "2023-05-17T13:10:53.268963Z"
        },
        "trusted": true,
        "id": "4IQYyS8sZ0qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size_encoder = num_encoder_tokens\n",
        "input_size_decoder = num_decoder_tokens\n",
        "output_size = num_decoder_tokens\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T13:11:59.411016Z",
          "iopub.execute_input": "2023-05-17T13:11:59.411585Z",
          "iopub.status.idle": "2023-05-17T13:12:00.576284Z",
          "shell.execute_reply.started": "2023-05-17T13:11:59.411542Z",
          "shell.execute_reply": "2023-05-17T13:12:00.575070Z"
        },
        "trusted": true,
        "id": "NyOpo8o8Z0qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_char_index(corpus):\n",
        "    char_index = defaultdict(int)\n",
        "    for i, char in enumerate(corpus):\n",
        "        if char not in char_index:\n",
        "            char_index[char] = i\n",
        "    return dict(char_index)\n",
        "\n",
        "input_char_index = create_char_index(input_corpus)\n",
        "output_char_index = create_char_index(output_corpus)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T13:12:00.762580Z",
          "iopub.execute_input": "2023-05-17T13:12:00.763269Z",
          "iopub.status.idle": "2023-05-17T13:12:00.829486Z",
          "shell.execute_reply.started": "2023-05-17T13:12:00.763223Z",
          "shell.execute_reply": "2023-05-17T13:12:00.828654Z"
        },
        "trusted": true,
        "id": "-tmC144fZ0qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X_train)):\n",
        "    x = X_train[i]\n",
        "    y = Y_train[i]\n",
        "    count=0\n",
        "    size = x.size\n",
        "    for t, char in enumerate(x):\n",
        "        input_data[t, i] = input_char_index[char]\n",
        "    count=count+1 \n",
        "    input_data[t + 1 :,i] = input_char_index[\" \"]\n",
        "    count1=1\n",
        "    for t, char in enumerate(y):\n",
        "        target_data[t, i] = output_char_index[char]\n",
        "        count1=count+1     \n",
        "    target_data[t + 1 :,i] = output_char_index[\" \"]\n",
        "    \n",
        "\n",
        "data_type = torch.int64\n",
        "data_type1=torch.float64\n",
        "for i in range(len(X_val)):\n",
        "    x=X_val[i]\n",
        "    y=Y_val[i]\n",
        "    count = 0\n",
        "    size - x.size\n",
        "    for t, char in enumerate(x):\n",
        "        input_data_val[t, i] = input_char_index[char]\n",
        "        count = count +1\n",
        "    input_data_val[t + 1 :,i] = input_char_index[\" \"]\n",
        "    \n",
        "    count = 0\n",
        "    for t, char in enumerate(y):\n",
        "        target_data_val[t, i] = output_char_index[char]\n",
        "        count = count +1\n",
        "            \n",
        "    target_data_val[t + 1 :,i] = output_char_index[\" \"]\n",
        "\n",
        "input_data_val = torch.tensor(input_data_val,dtype=data_type)\n",
        "target_data_val = torch.tensor(target_data_val,dtype=data_type)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T14:17:58.518511Z",
          "iopub.execute_input": "2023-05-17T14:17:58.518988Z",
          "iopub.status.idle": "2023-05-17T14:17:58.526878Z",
          "shell.execute_reply.started": "2023-05-17T14:17:58.518886Z",
          "shell.execute_reply": "2023-05-17T14:17:58.525330Z"
        },
        "trusted": true,
        "id": "ZACwd12EZ0qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_data = torch.tensor(input_data,dtype=data_type)\n",
        "reverse_input_char_index = {i: char for char, i in input_char_index.items()}\n",
        "reverse_target_char_index = {i: char for char, i in output_char_index.items()}\n",
        "target_data = torch.tensor(target_data,dtype=data_type)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T14:28:58.826785Z",
          "iopub.execute_input": "2023-05-17T14:28:58.827256Z",
          "iopub.status.idle": "2023-05-17T14:28:58.852965Z",
          "shell.execute_reply.started": "2023-05-17T14:28:58.827202Z",
          "shell.execute_reply": "2023-05-17T14:28:58.852103Z"
        },
        "trusted": true,
        "id": "4hYBVyAMZ0qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM RUN Only\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.2):\n",
        "        x = target[0]\n",
        "        variables = 0\n",
        "        target_vocab_size = num_decoder_tokens\n",
        "        input_vocab_size = num_encoder_tokens\n",
        "        outputs = torch.zeros(target.shape[0], source.shape[1], target_vocab_size).to(device)\n",
        "        \n",
        "        hidden, cell=self.encoder(source)\n",
        "        ht = hidden[-1, :, :]\n",
        "        res = cell[-1,:,:]\n",
        "\n",
        "        for t in range(1, target.shape[0]):\n",
        "            # Use previous hidden, cell as context from encoder at start\n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "\n",
        "            \n",
        "            outputs[t] = output\n",
        "            res = output[0:]\n",
        "          \n",
        "            best_guess = output.argmax(1)\n",
        "            \n",
        "            if random.random() < teacher_force_ratio:\n",
        "                x = target[t]\n",
        "            else:\n",
        "                x = best_guess\n",
        "\n",
        "        return outputs\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout,size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dropout,self.num_layers,self.bidirectional,self.embedding = nn.Dropout(dropout),num_layers,True,nn.Embedding(input_size, embedding_size)\n",
        "        self.hidden_size,self.identity_init,self.init_h0 = hidden_size,torch.eye(hidden_size),nn.Linear(num_layers * 2, num_layers)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout)\n",
        "        self.fc_hidden,self.fc_cell = nn.Linear(hidden_size * 2, hidden_size), nn.Linear(hidden_size * 2, hidden_size)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (seq_length, N) where N is batch size\n",
        "        a = self.embedding(x)\n",
        "        embedding = self.dropout(a)\n",
        "        identity_init = self.identity_init\n",
        "        embedded = self.embedding(x).view(1, 1, -1)\n",
        "        # embedding shape: (seq_length, N, embedding_size)\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding)\n",
        "        # outputs shape: (seq_length, N, hidden_size)\n",
        "        init_h0 = self.init_h0\n",
        "\n",
        "        return hidden, cell\n",
        "    def initHidden(self):\n",
        "        value = 1\n",
        "        return torch.zeros(value, value, self.hidden_size, device=device)\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout,beam_width):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dropout,self.num_layers,self.bidirectional,self.embedding = nn.Dropout(dropout), num_layers,True,nn.Embedding(input_size, embedding_size)\n",
        "        self.hidden_size,self.identity_init,self.init_h0 = hidden_size,torch.eye(hidden_size), nn.Linear(num_layers * 2, num_layers)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
        "        # is 1 here because we are sending in a single word and not a sentence\n",
        "        x = x.unsqueeze(0)\n",
        "        hid=hidden.squeeze(0)\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        embed=embedding[0:]\n",
        "        # embedding shape: (1, N, embedding_size)\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "        # outputs shape: (1, N, hidden_size)\n",
        "\n",
        "        predictions = self.fc(outputs).squeeze(0)\n",
        "        results=predictions[0:]\n",
        "        results = self.softmax(predictions)\n",
        "\n",
        "\n",
        "        return predictions, hidden, cell\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T14:18:02.578338Z",
          "iopub.execute_input": "2023-05-17T14:18:02.578742Z",
          "iopub.status.idle": "2023-05-17T14:18:02.600690Z",
          "shell.execute_reply.started": "2023-05-17T14:18:02.578712Z",
          "shell.execute_reply": "2023-05-17T14:18:02.599362Z"
        },
        "trusted": true,
        "id": "sbZHV9wLZ0qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search(model, word, input_char_index, output_char_index, reverse_input_char_index,\n",
        "                reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length,\n",
        "                num_encoder_tokens, num_decoder_tokens, beam_width, device, length_penalty=0.6):\n",
        "\n",
        "    word_t = ''\n",
        "    word_new = ''\n",
        "    \n",
        "    sizeofword = len(word)\n",
        "    data = np.zeros((max_encoder_seq_length, 1), dtype=\"int64\")\n",
        "    for i in range(sizeofword):\n",
        "        data[i, 0] = input_char_index[word[i]]\n",
        "    \n",
        "    data[sizeofword:, 0] = input_char_index[\" \"]\n",
        "    data = torch.tensor(data, dtype=torch.int64).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden,cell = model.encoder(data)\n",
        "    padding = '\\t'\n",
        "    value = 1\n",
        "    ovalue=-1\n",
        "    initial_sequence = torch.tensor(np.array(output_char_index[padding]).reshape(value,)).to(device)\n",
        "    zero = 0\n",
        "    res =hidden.unsqueeze(0)\n",
        "    beam = [(0.0, initial_sequence, hidden.unsqueeze(0))]  # [(score, sequence, hidden)]\n",
        "    start ='\\n'\n",
        "    for _ in range(max_decoder_seq_length):\n",
        "        candidates = []\n",
        "        options=[]\n",
        "        for score, seq, hidden in beam:\n",
        "            count = 0\n",
        "            last_token = seq[ovalue].item()\n",
        "            if last_token == output_char_index[start]:\n",
        "                # If the sequence ends with the end token, add it to the candidates\n",
        "                candidates.append((score, seq, hidden))\n",
        "                count =count+1\n",
        "                continue\n",
        "\n",
        "            x = torch.tensor(np.array(last_token).reshape(value,)).to(device)\n",
        "            output, hidden,cell = model.decoder(x, hidden.squeeze(0),cell)\n",
        "            res = output[0:]\n",
        "            probabilities = F.softmax(output, dim=1)\n",
        "            result =probabilities\n",
        "            # Get the top-k probabilities and tokens\n",
        "            topk_probs, topk_tokens = torch.topk(probabilities, k=beam_width)\n",
        "            tops = topk_probs[0]\n",
        "            topk = topk_tokens[0]\n",
        "            for prob, token in zip(tops, topk):\n",
        "                new_s= token.unsqueeze(0)\n",
        "                new_seq = torch.cat((seq, new_s), dim=0)\n",
        "                new_hidden = hidden.clone().unsqueeze(0)\n",
        "                penalty = len(new_seq) - 1\n",
        "                len_pen = length_penalty\n",
        "                length_penalty_factor = ((penalty) / 5) **  len_pen   # Adjust penalty factor as needed\n",
        "                candidates.append((score + torch.log(prob).item() / length_penalty_factor, new_seq, new_hidden))\n",
        "                options.append((score + torch.log(prob).item() / length_penalty_factor))\n",
        "        # Select top-k candidates based on the accumulated scores\n",
        "        beam = heapq.nlargest(beam_width, candidates, key=lambda x: x[0])\n",
        "\n",
        "    # Select the best sequence from the beam as the output\n",
        "    best_res = 0\n",
        "    word_pred=''\n",
        "    best_score, best_sequence, _ = max(beam, key=lambda x: x[0])\n",
        "    word_t = ''.join([reverse_target_char_index[val.item()] for val in best_sequence[value:ovalue]])\n",
        "    word_pred = word_t\n",
        "    return word_t"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T14:18:02.774587Z",
          "iopub.execute_input": "2023-05-17T14:18:02.774970Z",
          "iopub.status.idle": "2023-05-17T14:18:02.791182Z",
          "shell.execute_reply.started": "2023-05-17T14:18:02.774938Z",
          "shell.execute_reply": "2023-05-17T14:18:02.789993Z"
        },
        "trusted": true,
        "id": "PudHrXV1Z0qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "learning_rate = 0.001\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T14:18:02.992271Z",
          "iopub.execute_input": "2023-05-17T14:18:02.992755Z",
          "iopub.status.idle": "2023-05-17T14:18:03.000666Z",
          "shell.execute_reply.started": "2023-05-17T14:18:02.992715Z",
          "shell.execute_reply": "2023-05-17T14:18:02.999199Z"
        },
        "trusted": true,
        "id": "qzG80IH8Z0qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(num_encoder_tokens,input_embedding_size, dp, cell_type, hidden_size, num_enc_layers, num_dec_layers,num_epochs,output_size,input_size_decoder,batch_size,beam_width):\n",
        "    input = []\n",
        "    correct = []\n",
        "    decoded = []\n",
        "    ex = []\n",
        "    if(cell_type==\"LSTM\"):\n",
        "        encoder_net = Encoder(input_size_encoder,input_embedding_size, hidden_size, num_enc_layers,dp,output_size).to(device)\n",
        "        decoder_net = Decoder(input_size_decoder,input_embedding_size,hidden_size,output_size,num_dec_layers,dp,beam_width).to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        data_train = torch.split(input_data,batch_size,dim=1)\n",
        "        target_train = torch.split(target_data,batch_size,dim=1)\n",
        "        learning_rate=0.001\n",
        "        total_words = len(X_val)\n",
        "        model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        " \n",
        "        for epoch in range(num_epochs):\n",
        "            correct_output = 0\n",
        "            print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "            model.eval()\n",
        "            model.train()\n",
        "\n",
        "            train_size = len(data_train)\n",
        "            for i in range(train_size):\n",
        "                neg = -1\n",
        "                pos = 1\n",
        "                a = data_train[i]\n",
        "                b = target_train[i]\n",
        "               # Get input and targets and get to cuda\n",
        "                inp_data = a.to(device)\n",
        "                target = b.to(device)\n",
        "                # Forward prop\n",
        "                output = model(inp_data, target)\n",
        "                size = output.shape[2]\n",
        "                temp = output[pos:]\n",
        "                temp1 =temp.reshape(neg, size)\n",
        "                output = temp1\n",
        "                tar = target[pos:]\n",
        "                target = tar.reshape(neg)\n",
        "                optimizer.zero_grad()\n",
        "                loss = criterion(output, target)\n",
        "                # Back prop\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "                # Gradient descent step\n",
        "                optimizer.step()\n",
        "            model.eval()\n",
        "            \n",
        "            correct_prediction = 0\n",
        "            result_current = 0\n",
        "            for i in range(total_words):\n",
        "    \n",
        "                decoded_sentence = beam_search(model,X_val[i], input_char_index, output_char_index, reverse_input_char_index, \n",
        "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
        "              num_encoder_tokens, num_decoder_tokens,1,device)\n",
        "                true_output = Y_val[i][1:-1]\n",
        "                if true_output== decoded_sentence:\n",
        "                     correct_prediction =correct_prediction + 1\n",
        "            result_current = correct_prediction\n",
        "            test_accuracy = correct_prediction / total_words\n",
        "\n",
        "            print(test_accuracy)\n",
        "            wandb.log({'val_accuracy' : test_accuracy*100})\n",
        "        total_words = len(X_test)\n",
        "        correct_prediction = 0 \n",
        "        result_current = 0\n",
        "        for i in range(total_words):\n",
        "            decoded_sentence = beam_search(model,X_test[i], input_char_index, output_char_index, reverse_input_char_index, \n",
        "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
        "              num_encoder_tokens, num_decoder_tokens,1,device)\n",
        "            true_output = Y_test[i][1:-1]\n",
        "            if true_output == decoded_sentence:\n",
        "                  correct_prediction = correct_prediction+ 1\n",
        "        result_current = correct_prediction\n",
        "        test_accuracy = correct_prediction / total_words\n",
        "        print(\"Test Accuracy is :\")\n",
        "        print(test_accuracy)\n",
        " \n",
        "        np.random.seed(10)\n",
        "        for index in range(total_words):\n",
        "            decoded_sentence = beam_search(model,X_test[index], input_char_index, output_char_index, reverse_input_char_index, \n",
        "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
        "              num_encoder_tokens, num_decoder_tokens,1,device)\n",
        "            true_output = Y_test[index][pos:neg]\n",
        "            if true_output == decoded_sentence:\n",
        "                ex.append(\"Yes\")\n",
        "            else:\n",
        "                ex.append(\"No\")        \n",
        "        \n",
        "            input.append(X_test[index])\n",
        "            correct.append(Y_test[index][pos:neg])\n",
        "            decoded.append(decoded_sentence)\n",
        "        import pandas as pd\n",
        "\n",
        "        grid = {'Input Word': input, 'True Output' : correct, 'My Decoded Output' : decoded, \"Matching or Not\" : ex}\n",
        "\n",
        "        df=pd.DataFrame(grid)\n",
        "        #df= pd.DataFrame.from_dict(grid,orient='index')\n",
        "        df.to_csv('/content/drive/MyDrive/Assignment3/aksharantar_sampled/tel/Van.csv', index=False,header=True)\n",
        "        print(df.head(20))\n",
        "        pd.DataFrame(grid)\n",
        "        #print(pd.DataFrame(grid))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T14:18:03.161096Z",
          "iopub.execute_input": "2023-05-17T14:18:03.161726Z",
          "iopub.status.idle": "2023-05-17T14:18:03.169849Z",
          "shell.execute_reply.started": "2023-05-17T14:18:03.161692Z",
          "shell.execute_reply": "2023-05-17T14:18:03.168073Z"
        },
        "trusted": true,
        "id": "64lQkl50Z0qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key='17d991db26320e751b170877037d1067a164fe6d')\n",
        "wandb.init(project=\"Assignment_3_F\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T14:18:03.593931Z",
          "iopub.execute_input": "2023-05-17T14:18:03.594360Z",
          "iopub.status.idle": "2023-05-17T14:18:03.603072Z",
          "shell.execute_reply.started": "2023-05-17T14:18:03.594323Z",
          "shell.execute_reply": "2023-05-17T14:18:03.601401Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "5tvUPeNEZ0qt",
        "outputId": "bef173e2-c923-4bf1-a4c6-9fd726f7e4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m046\u001b[0m (\u001b[33mharshvrma\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230520_164119-vlu3c20k</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/harshvrma/Assignment_3_F/runs/vlu3c20k' target=\"_blank\">glamorous-dawn-24</a></strong> to <a href='https://wandb.ai/harshvrma/Assignment_3_F' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/harshvrma/Assignment_3_F' target=\"_blank\">https://wandb.ai/harshvrma/Assignment_3_F</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/harshvrma/Assignment_3_F/runs/vlu3c20k' target=\"_blank\">https://wandb.ai/harshvrma/Assignment_3_F/runs/vlu3c20k</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/harshvrma/Assignment_3_F/runs/vlu3c20k?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f2fc04e1bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training(input_size_encoder ,512, 0.3, \"LSTM\",512, 3, 3,40,num_decoder_tokens,num_decoder_tokens,512,3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-17T14:18:03.881722Z",
          "iopub.execute_input": "2023-05-17T14:18:03.882770Z",
          "iopub.status.idle": "2023-05-17T14:18:03.901253Z",
          "shell.execute_reply.started": "2023-05-17T14:18:03.882730Z",
          "shell.execute_reply": "2023-05-17T14:18:03.899739Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz5zGc3rZ0qt",
        "outputId": "bf091e75-9420-41db-85d1-65633ac0033b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0 / 40]\n",
            "0.0\n",
            "[Epoch 1 / 40]\n",
            "0.0\n",
            "[Epoch 2 / 40]\n",
            "0.0009765625\n",
            "[Epoch 3 / 40]\n",
            "0.049072265625\n",
            "[Epoch 4 / 40]\n",
            "0.18115234375\n",
            "[Epoch 5 / 40]\n",
            "0.292236328125\n",
            "[Epoch 6 / 40]\n",
            "0.35888671875\n",
            "[Epoch 7 / 40]\n",
            "0.385498046875\n",
            "[Epoch 8 / 40]\n",
            "0.42919921875\n",
            "[Epoch 9 / 40]\n",
            "0.4541015625\n",
            "[Epoch 10 / 40]\n",
            "0.466796875\n",
            "[Epoch 11 / 40]\n",
            "0.451171875\n",
            "[Epoch 12 / 40]\n",
            "0.489990234375\n",
            "[Epoch 13 / 40]\n",
            "0.498046875\n",
            "[Epoch 14 / 40]\n",
            "0.49853515625\n",
            "[Epoch 15 / 40]\n",
            "0.4990234375\n",
            "[Epoch 16 / 40]\n",
            "0.520751953125\n",
            "[Epoch 17 / 40]\n",
            "0.53173828125\n",
            "[Epoch 18 / 40]\n",
            "0.533203125\n",
            "[Epoch 19 / 40]\n",
            "0.531982421875\n",
            "[Epoch 20 / 40]\n",
            "0.51513671875\n",
            "[Epoch 21 / 40]\n",
            "0.537353515625\n",
            "[Epoch 22 / 40]\n",
            "0.5537109375\n",
            "[Epoch 23 / 40]\n",
            "0.553466796875\n",
            "[Epoch 24 / 40]\n",
            "0.551025390625\n",
            "[Epoch 25 / 40]\n",
            "0.564453125\n",
            "[Epoch 26 / 40]\n",
            "0.53857421875\n",
            "[Epoch 27 / 40]\n",
            "0.5478515625\n",
            "[Epoch 28 / 40]\n",
            "0.546142578125\n",
            "[Epoch 29 / 40]\n",
            "0.551025390625\n",
            "[Epoch 30 / 40]\n",
            "0.550048828125\n",
            "[Epoch 31 / 40]\n",
            "0.554931640625\n",
            "[Epoch 32 / 40]\n",
            "0.5595703125\n",
            "[Epoch 33 / 40]\n",
            "0.54638671875\n",
            "[Epoch 34 / 40]\n",
            "0.515869140625\n",
            "[Epoch 35 / 40]\n",
            "0.54052734375\n",
            "[Epoch 36 / 40]\n",
            "0.5595703125\n",
            "[Epoch 37 / 40]\n",
            "0.5693359375\n",
            "[Epoch 38 / 40]\n",
            "0.57080078125\n",
            "[Epoch 39 / 40]\n",
            "0.574462890625\n",
            "Test Accuracy is :\n",
            "0.519775390625\n",
            "           Input Word   True Output My Decoded Output Matching or Not\n",
            "0          vithananni   విత్తనాన్ని        విథనననననని              No\n",
            "1        prayaanikulu   ప్రయాణికులు       ప్రయాణికులు             Yes\n",
            "2              hassan          హసన్           హస్సాన్              No\n",
            "3            pakshala        పక్షాల             పక్షల              No\n",
            "4             goutham         గౌతమ్              గౌతం              No\n",
            "5       puraanamulanu    పురాణములను        పురాణములను             Yes\n",
            "6               union       యూనియన్           యూనియన్             Yes\n",
            "7             medassu       మేధస్సు           మెడస్సు              No\n",
            "8             kuantum      క్వాంటమ్           కుంంతుం              No\n",
            "9   aakaashaannayinaa  ఆకాశాన్నయినా      ఆకాషాన్నయినా              No\n",
            "10              naats        నాట్స్            నాట్స్             Yes\n",
            "11            jaavaed        జావేద్            జావెడ్              No\n",
            "12             powell        పావెల్            పౌవెల్              No\n",
            "13        deshamunaku      దేశమునకు          దేశమునకు             Yes\n",
            "14             dublin      డుబ్లిన్           డబ్లిన్              No\n",
            "15            cholera          కలరా            చోలేరా              No\n",
            "16           vatakara          వడగర             వాకకర              No\n",
            "17              silva        సిల్వా            సిల్వా             Yes\n",
            "18             patter         పాటర్           పాట్టర్              No\n",
            "19    praatipadikapai  ప్రాతిపదికపై      ప్రాతిపదికపై             Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQ48j2yZqT5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G6ADtLid8rtB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}